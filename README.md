# WebNet
 neural network in a web, not layer by layer, using adjacency matrix. Every timestep, it only goes one step. 
 for time-series stuff; RL-like. But instead of all those reward discount factor whatever, it's just a single backpropagation through an RNN-like architecture. 
